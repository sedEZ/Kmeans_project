{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abalone dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumn_names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\", \\n                \"shucked weight\", \"viscera weight\", \"shell weight\", \"rings\"]\\nabalone = pd.read_csv(\"./dataset/abalone.data\",names=column_names)\\n\\n#0,1,2 labeling sex\\ndata_x = abalone.drop(columns=[\"rings\"])\\ndata_x = data_x.replace([\\'M\\',\\'F\\',\\'I\\'],[0,1,2])\\n\\n#one-hot encoding\\ndfDummies = pd.get_dummies(data_x[\\'sex\\'], prefix = \\'sex\\')\\ndata_x = pd.concat([data_x.drop(columns=[\\'sex\\']), dfDummies], axis=1)\\n\\ndata_y = np.array(abalone[\"rings\"])\\ndata_y[data_y<11]    = 0\\ndata_y[data_y>=11]   = 1\\nSimulate_time = 10\\ndata_x\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_x : features (Dataframe)\n",
    "#data_y : labels   (np.array)\n",
    "'''\n",
    "column_names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\", \n",
    "                \"shucked weight\", \"viscera weight\", \"shell weight\", \"rings\"]\n",
    "abalone = pd.read_csv(\"./dataset/abalone.data\",names=column_names)\n",
    "\n",
    "#0,1,2 labeling sex\n",
    "data_x = abalone.drop(columns=[\"rings\"])\n",
    "data_x = data_x.replace(['M','F','I'],[0,1,2])\n",
    "\n",
    "#one-hot encoding\n",
    "dfDummies = pd.get_dummies(data_x['sex'], prefix = 'sex')\n",
    "data_x = pd.concat([data_x.drop(columns=['sex']), dfDummies], axis=1)\n",
    "\n",
    "data_y = np.array(abalone[\"rings\"])\n",
    "data_y[data_y<11]    = 0\n",
    "data_y[data_y>=11]   = 1\n",
    "Simulate_time = 10\n",
    "data_x\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_x : features (np.array)\n",
    "#data_y : labels   (np.array)\n",
    "spark = SparkSession \\\n",
    "                .builder \\\n",
    "                .appName(\"K-Means:origin\") \\\n",
    "                .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "                .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "line = sc.textFile(\"./dataset/c20d6n200000.txt\")\n",
    "data_x = spark.createDataFrame(line.map(lambda r : r.split(\",\")).collect()).toPandas()\n",
    "\n",
    "Simulate_time = 1\n",
    "K = 3\n",
    "\n",
    "converge_dist = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class our_k_means:\n",
    "    def __init__(self,data_x, K):\n",
    "        self.data_x = pd.DataFrame(preprocessing.scale(data_x))\n",
    "        \n",
    "        #資料特性\n",
    "        self.DCNT = len(self.data_x)               #資料個數\n",
    "        self.DIM  = len(self.data_x.columns)       #資料維度\n",
    "        self.K    = K                              #叢聚個數\n",
    "        #self.K    = np.amax(self.data_y)+1        #叢聚個數\n",
    "        self.MAX_ITER = 30                        #最大迭代 \n",
    "        self.MIN_PT = 0                            #最小變動點\n",
    "        \n",
    "        #k-means過程的參數\n",
    "        self.data =[]                       #data[DCNT][DIM]:資料\n",
    "        self.cent =[]                       #cent[K][DIM]   :各centroid的座標\n",
    "        self.table=[]                       #table[DCNT]    :各資料的所屬cluster\n",
    "        self.dis_k=[]                       #dis_k[K][DIM]  :各cluster的座標和\n",
    "        self.cent_c=[]                      #cent_c[K]      :各cluster的擁有資料數和\n",
    "        self.ch_pt = 0                      #ch_pt          :紀錄變動點個數\n",
    "        self.iterl = 0 \n",
    "        self.sse2 = 0\n",
    "        \n",
    "        #計算acc時的參數\n",
    "        self.origin_mass = []\n",
    "        self.cent_name = []\n",
    "        \n",
    "    \n",
    "    #run k-means    \n",
    "    def run(self):\n",
    "        \n",
    "        #initialize tables\n",
    "        self.kmeans_init()   #初始化centroid\n",
    "                \n",
    "        #first iteration \n",
    "        self.ch_pt = 0          \n",
    "        self.iterl = 0\n",
    "        self.sse2 = self.update_table()\n",
    "        sse1 = self.sse2-1\n",
    "        \n",
    "        \n",
    "        #update centroid & data clustering\n",
    "        while self.iterl<self.MAX_ITER and abs(sse1-self.sse2)>0.05 :\n",
    "            sse1 = self.sse2\n",
    "            self.iterl+=1\n",
    "            self.update_cent()\n",
    "            self.sse2 = self.update_table()\n",
    "            print(abs(self.sse2-sse1))\n",
    "        \n",
    "        self.table = self.table.astype(int)\n",
    "        \n",
    "        \n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "#------------------------------Subfunctions of run()------------------------------\n",
    "#---------------------------------------------------------------------------------    \n",
    "    def kmeans_init(self):\n",
    "        \n",
    "        self.data = self.data_x.values\n",
    "        self.cent = np.zeros((self.K,self.DIM))\n",
    "        self.table= np.zeros(self.DCNT)\n",
    "        self.dis_k= np.zeros((self.K,self.DIM))\n",
    "        self.cent_c=np.zeros(self.K)\n",
    "                \n",
    "        pick = []\n",
    "        counter = 0\n",
    "        while(counter<self.K):\n",
    "            rnd = random.randint(0,self.DCNT-1)\n",
    "            if(rnd not in pick):\n",
    "                pick.append(rnd)\n",
    "                counter=counter+1\n",
    "                \n",
    "        for i in range(self.K):\n",
    "            for j in range(self.DIM):\n",
    "                self.cent[i][j] = self.data[pick[i]][j] \n",
    "        \n",
    "    \n",
    "    def cal_distance(self,x,y):\n",
    "        sum = 0\n",
    "        for i in range(self.DIM):\n",
    "            sum = sum + (self.data[x][i]-self.cent[y][i])*( self.data[x][i]-self.cent[y][i])\n",
    "        return sum\n",
    "\n",
    "            \n",
    "    def update_table(self):\n",
    "        t_sse = 0\n",
    "        self.ch_pt = 0 \n",
    "        \n",
    "        for i in range(self.DCNT):\n",
    "            min_dis = self.cal_distance(i,0)\n",
    "            min_k=0\n",
    "            for j in range(1,self.K):\n",
    "                dis = self.cal_distance(i,j)\n",
    "                if(dis<min_dis):\n",
    "                    min_dis = dis\n",
    "                    min_k = j\n",
    "            self.ch_pt+=(self.table[i]!=min_k)\n",
    "            self.table[i] = min_k\n",
    "            self.cent_c[min_k] +=1\n",
    "            t_sse+=min_dis\n",
    "            for j in range(self.DIM):\n",
    "                self.dis_k[min_k][j]+=self.data[i][j]\n",
    "                \n",
    "        return t_sse\n",
    "\n",
    "    def update_cent(self):\n",
    "        for i in range(self.K):\n",
    "            for j in range(self.DIM):\n",
    "                if self.cent_c[i] != 0:\n",
    "                    self.cent[i][j] = self.dis_k[i][j]/self.cent_c[i]\n",
    "                else:\n",
    "                    self.cent[i][j] = self.dis_k[i][j]\n",
    "\n",
    "    def print_cent(self):\n",
    "        print(\"Centroids:\")\n",
    "        print(self.cent)\n",
    "\n",
    "    def print_result(self):\n",
    "        print(\"K means:\")\n",
    "        print(self.table)\n",
    "        print(\"sse = \",end='')\n",
    "        print(self.sse2)\n",
    "        print(\"ch_pt = \",end='')\n",
    "        print(self.ch_pt)\n",
    "        print(\"iter = \",end='')\n",
    "        print(self.iterl)     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here comes our k-means\n",
    "### Let's run for 1 time and check the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl32rodan/.conda/envs/rodan/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype object were all converted to float64 by the scale function.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383244.9965154341\n",
      "8884.10250949033\n",
      "3168.718579864828\n",
      "1440.9397754393285\n",
      "807.18328226218\n",
      "529.7460536226863\n",
      "395.289251187467\n",
      "315.9153376229806\n",
      "271.8688437063247\n",
      "242.66101575340144\n",
      "218.29773011803627\n",
      "201.47593350196257\n",
      "189.9994695878122\n",
      "177.26978130161297\n",
      "165.58151152392384\n",
      "155.76283880299889\n",
      "144.56890569336247\n",
      "135.2255418151617\n",
      "126.54755119769834\n",
      "118.77321510843467\n",
      "110.41746157337911\n",
      "102.5093450259883\n",
      "95.4896971808048\n",
      "87.95853491686285\n",
      "81.57216850738041\n",
      "76.09386691986583\n",
      "70.61524614854716\n",
      "65.45803576835897\n",
      "60.69230003154371\n",
      "56.19925281370524\n",
      "Centroids:\n",
      "[[-0.01343986  0.58024062  0.31009633 -0.90865086  0.48468029  0.49605311]\n",
      " [-0.00438008 -0.17928653 -0.30765258  0.49559251 -0.98736629 -0.11493114]\n",
      " [ 0.02564292 -0.49445572  0.08803391  0.41704802  0.9799146  -0.48647843]]\n",
      "Total time : 241.83338809013367\n"
     ]
    }
   ],
   "source": [
    "result = our_k_means(data_x,3)\n",
    "start = time.time()\n",
    "result.run()\n",
    "result.print_cent()\n",
    "end = time.time()\n",
    "print(\"Total time : \",end=\"\")\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids:\n",
      "[[-0.01343986  0.58024062  0.31009633 -0.90865086  0.48468029  0.49605311]\n",
      " [-0.00438008 -0.17928653 -0.30765258  0.49559251 -0.98736629 -0.11493114]\n",
      " [ 0.02564292 -0.49445572  0.08803391  0.41704802  0.9799146  -0.48647843]]\n"
     ]
    }
   ],
   "source": [
    "result.print_cent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then , we run it for (Simulate_time) times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for  10  times :  0.6681829063921474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6681829063921474"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate\n",
    "result.calculate_acc(Simulate_time)\n",
    "result.acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's run the k-means provides by sklearn\n",
    "### -Then we can estimate how good we've done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM  = len(data_x.columns)       #資料維度\n",
    "K    = len(np.unique(data_y))    #叢聚個數\n",
    "label= pd.DataFrame(data_y)\n",
    "\n",
    "\n",
    "def k_means_sklearn(x):\n",
    "    \n",
    "    # KMeans 演算法\n",
    "    kmeans_fit = cluster.KMeans(n_clusters = K).fit(x)\n",
    "\n",
    "    # 測試分群結果\n",
    "    cluster_labels = kmeans_fit.predict(x)\n",
    "    \n",
    "    return cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the clusters should be 1-D DataFrame which contains the same labels\n",
    "def find_mass(k,dim,table,data):\n",
    "    mass = np.zeros((k,dim))\n",
    "    num = np.zeros(k)\n",
    "    row_count = 0\n",
    "\n",
    "    for i in table.values:\n",
    "        for j in range(dim):\n",
    "            mass[i][j] += data.iloc[row_count][j]\n",
    "        row_count += 1\n",
    "        num[i] += 1\n",
    "        \n",
    "    for i in range(k):\n",
    "        for j in range(dim):\n",
    "            mass[i][j] /= num[i]\n",
    "    \n",
    "    return mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_closest(k,origin,after_clustering):\n",
    "    closest = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        min_dist=float(\"inf\")\n",
    "        for j in range(k):\n",
    "            dist = np.linalg.norm(after_clustering[i]-origin[j])\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                closest[i]=j\n",
    "    return closest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel(origin_table,rename_table,target):\n",
    "    target = target.replace(origin_table,rename_table)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_labels = k_means_sklearn(data_x) # sklearn.cluster.k_means_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A list that can be used to compared the order of label\n",
    "temp = np.arange(K)\n",
    "#Turn the labels trained by skilearn into DataFrame format\n",
    "cluster_labels = pd.DataFrame(cluster_labels)\n",
    "\n",
    "#Find the mass of data with trained labels\n",
    "mass_sklean_kmeans = find_mass(K,DIM,cluster_labels.iloc[0:,0],data_x)\n",
    "#Find tha mass of data with original labels\n",
    "mass_origin        = find_mass(K,DIM,label.iloc[0:,0],data_x)\n",
    "#Fine the correct cluster names & Relabel\n",
    "closest_sklearn    = calculate_closest(K,mass_origin,mass_sklean_kmeans).astype(int)\n",
    "cluster_labels     = relabel(temp,closest_sklearn ,cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5937275556619583"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Valid accuracy\n",
    "sklearn_acc = accuracy_score(data_y,cluster_labels)\n",
    "sklearn_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
